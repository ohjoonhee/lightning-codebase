# lightning.pytorch==2.0.0
name: my-experiment
version: my-version

seed_everything: 42
trainer:
  accelerator: auto
  precision: 16-mixed
  max_epochs: 300
  deterministic: true
  plugins:
    - AsyncCheckpointIO
  callbacks:
    - class_path: WandbAlert
      init_args:
        monitor: ${model_ckpt.monitor}
        mode: ${model_ckpt.mode}
    - class_path: ClassificationSampleLogger
      init_args:
        val_epochs: 1
        val_batches: 10
        val_samples_per_batch: 10

model:
  class_path: HFClassificationModel
  init_args:
    net: textattack/bert-base-uncased-yelp-polarity
    net_kwargs:
      num_labels: 2
    criterion: CrossEntropyLoss

data:
  class_path: HFIMDBDataModule
  init_args:
    root: data
    batch_size: 8
    val_split: 0.1
    num_workers: 4
    tokenizer: textattack/bert-base-uncased-yelp-polarity

optimizer:
  class_path: Adam
  init_args:
    lr: 1e-4
    weight_decay: 5e-4

lr_scheduler:
  class_path: CosineAnnealingLR
  init_args:
    T_max: ${trainer.max_epochs}

early_stopping:
  monitor: val/acc
  patience: 1000
  mode: max

model_ckpt:
  # dirpath: "gs://ecstatic-kirch-iqa-dacon"
  monitor: val/acc
  mode: max
  filename: "best-ep={epoch:02d}-val_acc={val/acc:.4f}"
  auto_insert_metric_name: false
# ckpt_path: logs/debug-resume/version_0/fit/checkpoints/last.ckpt

